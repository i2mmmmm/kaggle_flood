{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import BayesianRidge, SGDRegressor, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = pd.read_csv('submission_ens_round.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 반올림 함수 정의\n",
    "def custom_round(x):\n",
    "    # 소수점 셋째 자리 구하기\n",
    "    x_scaled = x * 100\n",
    "    decimal_part = x_scaled - tf.floor(x_scaled)\n",
    "    integer_part = tf.floor(x_scaled) / 100\n",
    "\n",
    "    # 규칙에 따라 반올림 처리\n",
    "    rounded_value = tf.where(decimal_part > 0.5, tf.math.ceil(x_scaled) / 100,\n",
    "                             tf.where(decimal_part < 0.5, tf.math.floor(x_scaled) / 100, x))\n",
    "    return rounded_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tensor = tf.convert_to_tensor(round['FloodProbability'])\n",
    "result = custom_round(tf_tensor)\n",
    "result_numpy = result.numpy()\n",
    "result_df = pd.DataFrame({'value': result_numpy})\n",
    "result_df\n",
    "round['FloodProbability'] = result_df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745300</th>\n",
       "      <td>1863257</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745301</th>\n",
       "      <td>1863258</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745302</th>\n",
       "      <td>1863259</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745303</th>\n",
       "      <td>1863260</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745304</th>\n",
       "      <td>1863261</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745305 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  FloodProbability\n",
       "0       1117957             0.580\n",
       "1       1117958             0.455\n",
       "2       1117959             0.450\n",
       "3       1117960             0.470\n",
       "4       1117961             0.470\n",
       "...         ...               ...\n",
       "745300  1863257             0.480\n",
       "745301  1863258             0.440\n",
       "745302  1863259             0.620\n",
       "745303  1863260             0.550\n",
       "745304  1863261             0.530\n",
       "\n",
       "[745305 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round.to_csv('submission_ens_round2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "round2 = round.sort_values(by=['FloodProbability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터와 test 데이터 로드\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 타겟 변수 분리\n",
    "target = 'FloodProbability'\n",
    "X_train = train.drop(columns=[target,'id'])\n",
    "y_train = train[target]\n",
    "X_test = test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X는 입력 특성 데이터, y는 이산형 종속 변수(목표 변수)입니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train_encoded, test_size=0.2, random_state=42) # 필요한 경우 데이터를 훈련 및 테스트 세트로 분할합니다.\n",
    "\n",
    "# Logistic Regression 모델을 초기화합니다.\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05508664271753491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        22\n",
      "           7       0.00      0.00      0.00        24\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        22\n",
      "          10       0.00      0.00      0.00        44\n",
      "          11       0.00      0.00      0.00        87\n",
      "          12       0.00      0.01      0.00       147\n",
      "          13       0.00      0.00      0.00       120\n",
      "          14       0.00      0.00      0.00       162\n",
      "          15       0.00      0.00      0.00       198\n",
      "          16       0.00      0.00      0.00       262\n",
      "          17       0.00      0.00      0.00       324\n",
      "          18       0.00      0.00      0.00       394\n",
      "          19       0.00      0.00      0.00       573\n",
      "          20       0.00      0.00      0.00       672\n",
      "          21       0.68      0.02      0.03       895\n",
      "          22       0.00      0.00      0.00       940\n",
      "          23       0.00      0.00      0.00       959\n",
      "          24       0.00      0.00      0.00      1161\n",
      "          25       0.00      0.00      0.00      1352\n",
      "          26       0.00      0.00      0.00      1685\n",
      "          27       0.00      0.00      0.00      1743\n",
      "          28       0.00      0.00      0.00      2152\n",
      "          29       0.00      0.00      0.00      2357\n",
      "          30       0.00      0.00      0.00      2779\n",
      "          31       0.00      0.00      0.00      2650\n",
      "          32       0.00      0.00      0.00      3119\n",
      "          33       0.09      0.00      0.00      3252\n",
      "          34       0.03      0.04      0.03      3413\n",
      "          35       0.04      0.05      0.05      3374\n",
      "          36       0.06      0.18      0.09      3523\n",
      "          37       0.04      0.07      0.05      3513\n",
      "          38       0.07      0.10      0.08      3288\n",
      "          39       0.05      0.11      0.07      3508\n",
      "          40       0.06      0.13      0.08      3241\n",
      "          41       0.06      0.10      0.08      3371\n",
      "          42       0.07      0.27      0.12      3334\n",
      "          43       0.07      0.02      0.03      2892\n",
      "          44       0.07      0.02      0.03      3027\n",
      "          45       0.08      0.37      0.13      3165\n",
      "          46       0.06      0.03      0.04      2885\n",
      "          47       0.03      0.05      0.03      2656\n",
      "          48       0.00      0.00      0.00      2388\n",
      "          49       0.00      0.00      0.00      2093\n",
      "          50       0.00      0.00      0.00      1882\n",
      "          51       0.00      0.00      0.00      1905\n",
      "          52       0.12      0.00      0.00      1614\n",
      "          53       0.00      0.00      0.00      1343\n",
      "          54       0.00      0.00      0.00      1174\n",
      "          55       0.00      0.00      0.00       919\n",
      "          56       0.00      0.00      0.00       890\n",
      "          57       0.00      0.00      0.00       811\n",
      "          58       0.00      0.00      0.00       573\n",
      "          59       0.00      0.00      0.00       549\n",
      "          60       0.00      0.00      0.00       469\n",
      "          61       0.00      0.00      0.00       332\n",
      "          62       0.00      0.00      0.00       276\n",
      "          63       0.00      0.00      0.00       200\n",
      "          64       0.00      0.00      0.00       209\n",
      "          65       0.00      0.00      0.00       136\n",
      "          66       0.00      0.00      0.00       118\n",
      "          67       0.00      0.00      0.00        77\n",
      "          68       0.00      0.00      0.00        82\n",
      "          69       0.00      0.00      0.00        73\n",
      "          70       0.00      0.00      0.00        34\n",
      "          71       0.00      0.00      0.00        26\n",
      "          72       0.00      0.00      0.00        10\n",
      "          73       0.00      0.00      0.00        13\n",
      "          74       0.00      0.00      0.00         9\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         7\n",
      "          77       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.06     91583\n",
      "   macro avg       0.02      0.02      0.01     91583\n",
      "weighted avg       0.04      0.06      0.03     91583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반올림되지 않은 원래의 타겟 값을 추정\n",
    "def estimate_original_targets(y_rounded):\n",
    "    estimates = []\n",
    "    for y in y_rounded:\n",
    "        estimates.append(np.arange(y - 0.0005, y + 0.0005, 0.0001))\n",
    "    return estimates\n",
    "\n",
    "original_target_estimates = estimate_original_targets(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 회귀 모델 준비\n",
    "models = [\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('Ridge', Ridge(alpha=1.0)),\n",
    "    ('Lasso', Lasso(alpha=0.1))\n",
    "]\n",
    "\n",
    "# 최적의 모델을 찾기 위한 변수 초기화\n",
    "best_model = None\n",
    "best_score = float('inf')\n",
    "best_predictions = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression, Score: 0.0004037003044660933\n",
      "Model: Ridge, Score: 0.0004037002417534846\n",
      "Model: Lasso, Score: 0.0026036604621197416\n"
     ]
    }
   ],
   "source": [
    "# 다양한 회귀 모델을 학습 및 평가\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_train)\n",
    "    predictions_rounded = np.round(predictions, 4)\n",
    "    score = mean_squared_error(y_train, predictions_rounded)\n",
    "    \n",
    "    print(f'Model: {name}, Score: {score}')\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_predictions = predictions_rounded\n",
    "# 0.00040395088979260915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Ridge(), Best Score: 0.0004037002417534846\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Model: {best_model}, Best Score: {best_score}')\n",
    "\n",
    "# test 데이터에 대해 예측 수행\n",
    "test_predictions = best_model.predict(X_test)\n",
    "test_predictions_rounded = np.round(test_predictions, 4)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({'Id': test.index, 'target': test_predictions_rounded})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 반올림 함수 정의\n",
    "def custom_round(x):\n",
    "    # 소수점 셋째 자리 구하기\n",
    "    x_scaled = x * 100\n",
    "    decimal_part = x_scaled - tf.floor(x_scaled)\n",
    "    integer_part = tf.floor(x_scaled) / 100\n",
    "\n",
    "    # 규칙에 따라 반올림 처리\n",
    "    rounded_value = tf.where(decimal_part > 0.5, tf.math.ceil(x_scaled) / 100,\n",
    "                             tf.where(decimal_part < 0.5, tf.math.floor(x_scaled) / 100, x))\n",
    "    return rounded_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.33>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_round(0.328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>...</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.445</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.450</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "0                 5                   8                5              8   \n",
       "1                 6                   7                4              4   \n",
       "2                 6                   5                6              7   \n",
       "3                 3                   4                6              5   \n",
       "4                 5                   3                2              6   \n",
       "\n",
       "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
       "0             6              4            4          3                      3   \n",
       "1             8              8            3          5                      4   \n",
       "2             3              7            1          5                      4   \n",
       "3             4              8            4          7                      6   \n",
       "4             4              4            3          3                      3   \n",
       "\n",
       "   Encroachments  ...  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "0              4  ...                     3           3           5   \n",
       "1              6  ...                     2           0           3   \n",
       "2              5  ...                     3           7           5   \n",
       "3              8  ...                     4           7           4   \n",
       "4              3  ...                     2           6           6   \n",
       "\n",
       "   DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "0                            4                7            5   \n",
       "1                            5                3            3   \n",
       "2                            6                8            2   \n",
       "3                            4                6            5   \n",
       "4                            4                1            2   \n",
       "\n",
       "   InadequatePlanning  PoliticalFactors  FloodProbability  sum  \n",
       "0                   7                 3             0.445   94  \n",
       "1                   4                 3             0.450   94  \n",
       "2                   3                 3             0.530   99  \n",
       "3                   7                 5             0.535  104  \n",
       "4                   3                 5             0.415   72  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train.copy()\n",
    "BASE_FEATURES = X_test.columns\n",
    "train2['sum'] = train[BASE_FEATURES].sum(axis=1)\n",
    "train2 = train2.drop(columns =['id'])\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train2.sort_values(by=['FloodProbability','sum'])\n",
    "train3.to_csv('train3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.285, 0.315, 0.32 , 0.325, 0.33 , 0.335, 0.34 , 0.345, 0.35 ,\n",
       "       0.355, 0.36 , 0.365, 0.37 , 0.375, 0.38 , 0.385, 0.39 , 0.395,\n",
       "       0.4  , 0.405, 0.41 , 0.415, 0.42 , 0.425, 0.43 , 0.435, 0.44 ,\n",
       "       0.445, 0.45 , 0.455, 0.46 , 0.465, 0.47 , 0.475, 0.48 , 0.485,\n",
       "       0.49 , 0.495, 0.5  , 0.505, 0.51 , 0.515, 0.52 , 0.525, 0.53 ,\n",
       "       0.535, 0.54 , 0.545, 0.55 , 0.555, 0.56 , 0.565, 0.57 , 0.575,\n",
       "       0.58 , 0.585, 0.59 , 0.595, 0.6  , 0.605, 0.61 , 0.615, 0.62 ,\n",
       "       0.625, 0.63 , 0.635, 0.64 , 0.645, 0.65 , 0.655, 0.66 , 0.665,\n",
       "       0.67 , 0.675, 0.68 , 0.685, 0.69 , 0.695, 0.7  , 0.705, 0.71 ,\n",
       "       0.715, 0.725])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.FloodProbability.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 분리\n",
    "target = 'FloodProbability'\n",
    "X_train = train2.drop(columns=[target,'id'])\n",
    "y_train = train2[target]\n",
    "X_test = test.drop(columns=[target,'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "target = 'FloodProbability'\n",
    "# 타겟 값을 범주형 값으로 인코딩\n",
    "le = LabelEncoder()\n",
    "train['target_encoded'] = le.fit_transform(train[target])\n",
    "\n",
    "filtered_train = train[train[target].isin([0.285, 0.315, 0.32 , 0.325, 0.33 , 0.335, 0.34 , 0.345, 0.35 ,0.355, 0.36])]\n",
    "\n",
    "train2 = filtered_train.drop(columns=['id'])\n",
    "test2 = test.drop(columns=['id'])\n",
    "\n",
    "\n",
    "# # 타겟 값을 구간으로 변환\n",
    "# n_bins = 83  # 원하는 구간의 수\n",
    "# kbins = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "# train2['target_binned'] = kbins.fit_transform(train2[[target]])\n",
    "\n",
    "# # 독립 변수와 종속 변수 분리\n",
    "# X_train = train2.drop(columns=[target, 'target_binned']).values\n",
    "# y_train = train2['target_binned'].values\n",
    "# X_test = test2.values\n",
    "\n",
    "# # 학습 데이터와 검증 데이터 분리\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.05940844986433704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00        18\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        24\n",
      "          10       0.00      0.00      0.00        36\n",
      "          11       0.00      0.00      0.00        60\n",
      "          12       0.00      0.00      0.00        94\n",
      "          13       0.00      0.00      0.00        73\n",
      "          14       0.00      0.00      0.00       142\n",
      "          15       0.00      0.00      0.00       133\n",
      "          16       0.00      0.00      0.00       152\n",
      "          17       0.17      0.00      0.01       252\n",
      "          18       0.00      0.00      0.00       277\n",
      "          19       0.11      0.01      0.01       391\n",
      "          20       0.11      0.02      0.03       517\n",
      "          21       0.38      0.76      0.51       674\n",
      "          22       0.08      0.02      0.03       688\n",
      "          23       0.04      0.00      0.01       708\n",
      "          24       0.06      0.02      0.03       839\n",
      "          25       0.03      0.01      0.01      1000\n",
      "          26       0.05      0.03      0.04      1182\n",
      "          27       0.03      0.01      0.01      1257\n",
      "          28       0.05      0.05      0.05      1591\n",
      "          29       0.05      0.06      0.05      1676\n",
      "          30       0.05      0.07      0.06      1968\n",
      "          31       0.04      0.03      0.04      1889\n",
      "          32       0.05      0.09      0.07      2255\n",
      "          33       0.05      0.08      0.06      2394\n",
      "          34       0.06      0.10      0.07      2436\n",
      "          35       0.04      0.07      0.05      2430\n",
      "          36       0.06      0.11      0.08      2596\n",
      "          37       0.04      0.07      0.05      2513\n",
      "          38       0.05      0.06      0.06      2444\n",
      "          39       0.05      0.06      0.05      2489\n",
      "          40       0.04      0.05      0.04      2467\n",
      "          41       0.05      0.06      0.05      2392\n",
      "          42       0.04      0.05      0.05      2507\n",
      "          43       0.07      0.07      0.07      2244\n",
      "          44       0.05      0.05      0.05      2300\n",
      "          45       0.07      0.11      0.09      2385\n",
      "          46       0.05      0.04      0.05      2176\n",
      "          47       0.08      0.09      0.08      1988\n",
      "          48       0.05      0.03      0.04      1706\n",
      "          49       0.04      0.01      0.02      1505\n",
      "          50       0.05      0.02      0.03      1371\n",
      "          51       0.07      0.05      0.06      1349\n",
      "          52       0.08      0.03      0.05      1186\n",
      "          53       0.06      0.03      0.04       988\n",
      "          54       0.07      0.02      0.03       907\n",
      "          55       0.03      0.00      0.00       712\n",
      "          56       0.04      0.00      0.01       651\n",
      "          57       0.00      0.00      0.00       593\n",
      "          58       0.06      0.00      0.01       455\n",
      "          59       0.10      0.01      0.02       418\n",
      "          60       0.04      0.00      0.01       336\n",
      "          61       0.00      0.00      0.00       272\n",
      "          62       0.00      0.00      0.00       220\n",
      "          63       0.00      0.00      0.00       164\n",
      "          64       0.00      0.00      0.00       131\n",
      "          65       0.00      0.00      0.00        99\n",
      "          66       0.20      0.01      0.02        81\n",
      "          67       0.00      0.00      0.00        49\n",
      "          68       0.00      0.00      0.00        50\n",
      "          69       0.00      0.00      0.00        45\n",
      "          70       0.00      0.00      0.00        34\n",
      "          71       0.00      0.00      0.00        17\n",
      "          72       0.00      0.00      0.00         9\n",
      "          73       0.00      0.00      0.00         8\n",
      "          74       0.00      0.00      0.00         4\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         4\n",
      "          77       0.00      0.00      0.00         3\n",
      "          78       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.06     67078\n",
      "   macro avg       0.04      0.03      0.03     67078\n",
      "weighted avg       0.05      0.06      0.05     67078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mm\\anaconda3\\envs\\flood\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# 타겟 값이 이미 구간화되어 있는 경우, 범주형 값으로 변환\n",
    "y_train = train2['target_encoded'].values  # 이미 구간화된 타겟 값을 사용\n",
    "\n",
    "# 독립 변수 분리\n",
    "X_train = train2.drop(columns=[target,'target_encoded']).values\n",
    "X_test = test2.values\n",
    "\n",
    "# 데이터 샘플링 (예: 전체 데이터의 30%만 사용)\n",
    "# X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=0.3, random_state=42)\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_sample, y_train_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# 분류 모델 학습\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 검증 데이터에 대한 예측\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# 성능 평가\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 타겟 값 구간 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=train['target_binned'])\n",
    "plt.title('Target Binned Distribution')\n",
    "plt.xlabel('Target Binned')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 검증 데이터 예측 값 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y_val_pred)\n",
    "plt.title('Validation Predictions Distribution')\n",
    "plt.xlabel('Predicted Target Binned')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values  # 훈련 데이터 입력 특성\n",
    "y_train = data_train['FloodProbability'].values  # 훈련 데이터 타겟 변수\n",
    "\n",
    "X_test = data_test.drop(['id'], axis=1).values  # 테스트 데이터 입력 특성\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # 출력 뉴런 하나 (홍수 발생 가능성)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = pd.read_csv('submission_ens_round.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27949/27949 [==============================] - 35s 1ms/step - loss: 6.6095e-04 - mae: 0.0176 - val_loss: 3.7358e-04 - val_mae: 0.0149\n",
      "Epoch 2/50\n",
      "27907/27949 [============================>.] - ETA: 0s - loss: 3.7133e-04 - mae: 0.0152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 테스트 데이터의 타겟 변수 예측\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mm\\anaconda3\\envs\\page\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test Loss: 0.0003681324888020754\n",
    "# Test MAE: 0.015425443649291992\n",
    "# 데이터 불러오기\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values  # 훈련 데이터 입력 특성\n",
    "y_train = data_train['FloodProbability'].values  # 훈련 데이터 타겟 변수\n",
    "\n",
    "X_test = data_test.drop(['id'], axis=1).values  # 테스트 데이터 입력 특성\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # 출력 뉴런 하나 (홍수 발생 가능성)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "#0.860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 6.5333e-04 - mae: 0.0175 - val_loss: 3.7532e-04 - val_mae: 0.0156\n",
      "Epoch 2/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.7268e-04 - mae: 0.0152 - val_loss: 3.6519e-04 - val_mae: 0.0152\n",
      "Epoch 3/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6843e-04 - mae: 0.0151 - val_loss: 3.7696e-04 - val_mae: 0.0156\n",
      "Epoch 4/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6711e-04 - mae: 0.0151 - val_loss: 3.5927e-04 - val_mae: 0.0148\n",
      "Epoch 5/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6605e-04 - mae: 0.0150 - val_loss: 3.6076e-04 - val_mae: 0.0149\n",
      "Epoch 6/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6534e-04 - mae: 0.0150 - val_loss: 3.6253e-04 - val_mae: 0.0149\n",
      "Epoch 7/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6459e-04 - mae: 0.0150 - val_loss: 3.6094e-04 - val_mae: 0.0150\n",
      "Epoch 8/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6393e-04 - mae: 0.0150 - val_loss: 3.5833e-04 - val_mae: 0.0149\n",
      "Epoch 9/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6305e-04 - mae: 0.0150 - val_loss: 3.6792e-04 - val_mae: 0.0153\n",
      "Epoch 10/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6290e-04 - mae: 0.0150 - val_loss: 3.8121e-04 - val_mae: 0.0149\n",
      "Epoch 11/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6251e-04 - mae: 0.0150 - val_loss: 3.5880e-04 - val_mae: 0.0150\n",
      "Epoch 12/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6197e-04 - mae: 0.0150 - val_loss: 3.6681e-04 - val_mae: 0.0148\n",
      "Epoch 13/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6195e-04 - mae: 0.0150 - val_loss: 3.6766e-04 - val_mae: 0.0153\n",
      "Epoch 14/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6149e-04 - mae: 0.0149 - val_loss: 3.6349e-04 - val_mae: 0.0150\n",
      "Epoch 15/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6170e-04 - mae: 0.0149 - val_loss: 3.6193e-04 - val_mae: 0.0148\n",
      "Epoch 16/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6157e-04 - mae: 0.0150 - val_loss: 3.6223e-04 - val_mae: 0.0149\n",
      "Epoch 17/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6149e-04 - mae: 0.0149 - val_loss: 3.6335e-04 - val_mae: 0.0152\n",
      "Epoch 18/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6138e-04 - mae: 0.0149 - val_loss: 3.6085e-04 - val_mae: 0.0151\n",
      "Epoch 19/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6098e-04 - mae: 0.0149 - val_loss: 3.6137e-04 - val_mae: 0.0151\n",
      "Epoch 20/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6100e-04 - mae: 0.0149 - val_loss: 3.6186e-04 - val_mae: 0.0150\n",
      "Epoch 21/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6079e-04 - mae: 0.0149 - val_loss: 3.6074e-04 - val_mae: 0.0147\n",
      "Epoch 22/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6055e-04 - mae: 0.0149 - val_loss: 3.6117e-04 - val_mae: 0.0151\n",
      "Epoch 23/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6054e-04 - mae: 0.0149 - val_loss: 3.7965e-04 - val_mae: 0.0158\n",
      "Epoch 24/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6045e-04 - mae: 0.0149 - val_loss: 3.5664e-04 - val_mae: 0.0148\n",
      "Epoch 25/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6037e-04 - mae: 0.0149 - val_loss: 3.6083e-04 - val_mae: 0.0148\n",
      "Epoch 26/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6023e-04 - mae: 0.0149 - val_loss: 3.5677e-04 - val_mae: 0.0148\n",
      "Epoch 27/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.5998e-04 - mae: 0.0149 - val_loss: 3.5798e-04 - val_mae: 0.0147\n",
      "Epoch 28/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6006e-04 - mae: 0.0149 - val_loss: 3.6298e-04 - val_mae: 0.0152\n",
      "Epoch 29/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6023e-04 - mae: 0.0149 - val_loss: 3.6236e-04 - val_mae: 0.0152\n",
      "Epoch 30/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6011e-04 - mae: 0.0149 - val_loss: 3.6831e-04 - val_mae: 0.0154\n",
      "5241/5241 [==============================] - 5s 946us/step - loss: 3.6813e-04 - mae: 0.0154\n",
      "Test Loss: 0.0003681324888020754\n",
      "Test MAE: 0.015425443649291992\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# 입력과 출력 데이터 나누기\n",
    "X = data.drop(['FloodProbability','id'], axis=1).values  # 입력 특성\n",
    "y = data['FloodProbability'].values  # 출력 타겟\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=35)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))  # 더 많은 뉴런 추가\n",
    "model.add(Dense(64, activation='relu'))   # 추가적인 레이어\n",
    "model.add(Dense(1))  # 출력 뉴런 하나 (홍수 발생 가능성)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27949/27949 [==============================] - 41s 1ms/step - loss: 6.0796e-04 - mae: 0.0172 - val_loss: 3.9237e-04 - val_mae: 0.0160\n",
      "Epoch 2/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.7322e-04 - mae: 0.0152 - val_loss: 3.8872e-04 - val_mae: 0.0150\n",
      "Epoch 3/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6918e-04 - mae: 0.0151 - val_loss: 3.6249e-04 - val_mae: 0.0151\n",
      "Epoch 4/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6679e-04 - mae: 0.0151 - val_loss: 3.6367e-04 - val_mae: 0.0152\n",
      "Epoch 5/50\n",
      "27949/27949 [==============================] - 38s 1ms/step - loss: 3.6489e-04 - mae: 0.0150 - val_loss: 3.6551e-04 - val_mae: 0.0153\n",
      "Epoch 6/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6376e-04 - mae: 0.0150 - val_loss: 3.5923e-04 - val_mae: 0.0148\n",
      "Epoch 7/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6278e-04 - mae: 0.0150 - val_loss: 3.5992e-04 - val_mae: 0.0150\n",
      "Epoch 8/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6182e-04 - mae: 0.0149 - val_loss: 3.5814e-04 - val_mae: 0.0149\n",
      "Epoch 9/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6130e-04 - mae: 0.0149 - val_loss: 3.6010e-04 - val_mae: 0.0149\n",
      "Epoch 10/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6105e-04 - mae: 0.0149 - val_loss: 3.5936e-04 - val_mae: 0.0150\n",
      "Epoch 11/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6090e-04 - mae: 0.0149 - val_loss: 3.6246e-04 - val_mae: 0.0149\n",
      "Epoch 12/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6081e-04 - mae: 0.0149 - val_loss: 3.5822e-04 - val_mae: 0.0150\n",
      "Epoch 13/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6076e-04 - mae: 0.0149 - val_loss: 3.6270e-04 - val_mae: 0.0153\n",
      "Epoch 14/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6069e-04 - mae: 0.0149 - val_loss: 3.5828e-04 - val_mae: 0.0149\n",
      "Epoch 15/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6046e-04 - mae: 0.0149 - val_loss: 3.6168e-04 - val_mae: 0.0148\n",
      "Epoch 16/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6031e-04 - mae: 0.0149 - val_loss: 3.5849e-04 - val_mae: 0.0148\n",
      "Epoch 17/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6038e-04 - mae: 0.0149 - val_loss: 3.5831e-04 - val_mae: 0.0148\n",
      "Epoch 18/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6016e-04 - mae: 0.0149 - val_loss: 3.6075e-04 - val_mae: 0.0148\n",
      "Epoch 19/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6029e-04 - mae: 0.0149 - val_loss: 3.7849e-04 - val_mae: 0.0148\n",
      "Epoch 20/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6029e-04 - mae: 0.0149 - val_loss: 3.5980e-04 - val_mae: 0.0147\n",
      "Epoch 21/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6018e-04 - mae: 0.0149 - val_loss: 3.6103e-04 - val_mae: 0.0148\n",
      "Epoch 22/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5990e-04 - mae: 0.0149 - val_loss: 3.6147e-04 - val_mae: 0.0151\n",
      "Epoch 23/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6002e-04 - mae: 0.0149 - val_loss: 3.6160e-04 - val_mae: 0.0151\n",
      "Epoch 24/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5991e-04 - mae: 0.0149 - val_loss: 3.5755e-04 - val_mae: 0.0150\n",
      "Epoch 25/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5998e-04 - mae: 0.0149 - val_loss: 3.6838e-04 - val_mae: 0.0155\n",
      "Epoch 26/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5976e-04 - mae: 0.0149 - val_loss: 3.5748e-04 - val_mae: 0.0148\n",
      "Epoch 27/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5970e-04 - mae: 0.0149 - val_loss: 3.5834e-04 - val_mae: 0.0147\n",
      "Epoch 28/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5960e-04 - mae: 0.0149 - val_loss: 3.5635e-04 - val_mae: 0.0148\n",
      "Epoch 29/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5950e-04 - mae: 0.0149 - val_loss: 3.6449e-04 - val_mae: 0.0146\n",
      "Epoch 30/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5828e-04 - val_mae: 0.0151\n",
      "Epoch 31/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5952e-04 - mae: 0.0149 - val_loss: 3.5993e-04 - val_mae: 0.0151\n",
      "Epoch 32/50\n",
      "27949/27949 [==============================] - 41s 1ms/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5669e-04 - val_mae: 0.0149\n",
      "Epoch 33/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5926e-04 - mae: 0.0149 - val_loss: 3.5813e-04 - val_mae: 0.0150\n",
      "Epoch 34/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5947e-04 - mae: 0.0149 - val_loss: 3.6359e-04 - val_mae: 0.0146\n",
      "Epoch 35/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5934e-04 - mae: 0.0149 - val_loss: 3.5838e-04 - val_mae: 0.0150\n",
      "Epoch 36/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5945e-04 - mae: 0.0149 - val_loss: 3.5925e-04 - val_mae: 0.0151\n",
      "Epoch 37/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5952e-04 - mae: 0.0149 - val_loss: 3.5879e-04 - val_mae: 0.0148\n",
      "Epoch 38/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5932e-04 - mae: 0.0149 - val_loss: 3.6859e-04 - val_mae: 0.0148\n",
      "Epoch 39/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5943e-04 - mae: 0.0149 - val_loss: 3.5752e-04 - val_mae: 0.0149\n",
      "Epoch 40/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5914e-04 - mae: 0.0149 - val_loss: 3.5834e-04 - val_mae: 0.0150\n",
      "Epoch 41/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5936e-04 - mae: 0.0149 - val_loss: 3.5798e-04 - val_mae: 0.0149\n",
      "Epoch 42/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5930e-04 - mae: 0.0149 - val_loss: 3.5751e-04 - val_mae: 0.0147\n",
      "Epoch 43/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5927e-04 - mae: 0.0149 - val_loss: 3.6676e-04 - val_mae: 0.0153\n",
      "Epoch 44/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5916e-04 - mae: 0.0149 - val_loss: 3.5989e-04 - val_mae: 0.0151\n",
      "Epoch 45/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5929e-04 - mae: 0.0149 - val_loss: 3.5817e-04 - val_mae: 0.0147\n",
      "Epoch 46/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5911e-04 - mae: 0.0149 - val_loss: 3.5968e-04 - val_mae: 0.0151\n",
      "Epoch 47/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5925e-04 - mae: 0.0149 - val_loss: 3.6505e-04 - val_mae: 0.0147\n",
      "Epoch 48/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5922e-04 - mae: 0.0149 - val_loss: 3.6508e-04 - val_mae: 0.0147\n",
      "Epoch 49/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5920e-04 - mae: 0.0149 - val_loss: 3.7208e-04 - val_mae: 0.0156\n",
      "Epoch 50/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5931e-04 - mae: 0.0149 - val_loss: 3.6481e-04 - val_mae: 0.0147\n",
      "23291/23291 [==============================] - 18s 757us/step\n"
     ]
    }
   ],
   "source": [
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values  # 훈련 데이터 입력 특성\n",
    "y_train = data_train['FloodProbability'].values  # 훈련 데이터 타겟 변수\n",
    "\n",
    "X_test = data_test.drop(['id'], axis=1).values  # 테스트 데이터 입력 특성\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))  # 더 많은 뉴런 추가\n",
    "model.add(Dense(64, activation='relu'))   # 추가적인 레이어\n",
    "model.add(Dense(1))  # 출력 뉴런 하나 (홍수 발생 가능성)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "page",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
