{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12228/12228 [==============================] - 8s 685us/step - loss: 7.4663e-04 - mae: 0.0187 - val_loss: 3.9406e-04 - val_mae: 0.0157\n",
      "Epoch 2/100\n",
      "12228/12228 [==============================] - 8s 635us/step - loss: 3.8103e-04 - mae: 0.0154 - val_loss: 3.6540e-04 - val_mae: 0.0151\n",
      "Epoch 3/100\n",
      "12228/12228 [==============================] - 8s 640us/step - loss: 3.7227e-04 - mae: 0.0152 - val_loss: 3.7141e-04 - val_mae: 0.0150\n",
      "Epoch 4/100\n",
      "12228/12228 [==============================] - 8s 640us/step - loss: 3.7029e-04 - mae: 0.0151 - val_loss: 3.6337e-04 - val_mae: 0.0151\n",
      "Epoch 5/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6954e-04 - mae: 0.0151 - val_loss: 3.6951e-04 - val_mae: 0.0150\n",
      "Epoch 6/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6847e-04 - mae: 0.0151 - val_loss: 3.7194e-04 - val_mae: 0.0154\n",
      "Epoch 7/100\n",
      "12228/12228 [==============================] - 8s 629us/step - loss: 3.6764e-04 - mae: 0.0151 - val_loss: 3.7213e-04 - val_mae: 0.0150\n",
      "Epoch 8/100\n",
      "12228/12228 [==============================] - 8s 633us/step - loss: 3.6706e-04 - mae: 0.0151 - val_loss: 3.6705e-04 - val_mae: 0.0151\n",
      "Epoch 9/100\n",
      "12228/12228 [==============================] - 8s 642us/step - loss: 3.6642e-04 - mae: 0.0151 - val_loss: 3.8926e-04 - val_mae: 0.0160\n",
      "Epoch 10/100\n",
      "12228/12228 [==============================] - 8s 642us/step - loss: 3.6592e-04 - mae: 0.0151 - val_loss: 3.7015e-04 - val_mae: 0.0154\n",
      "Epoch 11/100\n",
      "12228/12228 [==============================] - 8s 673us/step - loss: 3.6554e-04 - mae: 0.0150 - val_loss: 3.6123e-04 - val_mae: 0.0149\n",
      "Epoch 12/100\n",
      "12228/12228 [==============================] - 8s 638us/step - loss: 3.6503e-04 - mae: 0.0150 - val_loss: 3.6258e-04 - val_mae: 0.0151\n",
      "Epoch 13/100\n",
      "12228/12228 [==============================] - 8s 643us/step - loss: 3.6484e-04 - mae: 0.0150 - val_loss: 3.6199e-04 - val_mae: 0.0149\n",
      "Epoch 14/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6456e-04 - mae: 0.0150 - val_loss: 3.6614e-04 - val_mae: 0.0150\n",
      "Epoch 15/100\n",
      "12228/12228 [==============================] - 8s 674us/step - loss: 3.6459e-04 - mae: 0.0150 - val_loss: 3.6082e-04 - val_mae: 0.0150\n",
      "Epoch 16/100\n",
      "12228/12228 [==============================] - 8s 647us/step - loss: 3.6461e-04 - mae: 0.0150 - val_loss: 3.6211e-04 - val_mae: 0.0148\n",
      "Epoch 17/100\n",
      "12228/12228 [==============================] - 8s 648us/step - loss: 3.6469e-04 - mae: 0.0150 - val_loss: 3.6459e-04 - val_mae: 0.0148\n",
      "Epoch 18/100\n",
      "12228/12228 [==============================] - 8s 651us/step - loss: 3.6446e-04 - mae: 0.0150 - val_loss: 3.6215e-04 - val_mae: 0.0151\n",
      "Epoch 19/100\n",
      "12228/12228 [==============================] - 8s 636us/step - loss: 3.6442e-04 - mae: 0.0150 - val_loss: 3.6190e-04 - val_mae: 0.0150\n",
      "Epoch 20/100\n",
      "12228/12228 [==============================] - 8s 631us/step - loss: 3.6445e-04 - mae: 0.0150 - val_loss: 3.6367e-04 - val_mae: 0.0150\n",
      "Epoch 21/100\n",
      "12228/12228 [==============================] - 8s 635us/step - loss: 3.6418e-04 - mae: 0.0150 - val_loss: 3.6347e-04 - val_mae: 0.0149\n",
      "Epoch 22/100\n",
      "12228/12228 [==============================] - 8s 648us/step - loss: 3.6403e-04 - mae: 0.0150 - val_loss: 3.6428e-04 - val_mae: 0.0151\n",
      "Epoch 23/100\n",
      "12228/12228 [==============================] - 8s 673us/step - loss: 3.6391e-04 - mae: 0.0150 - val_loss: 3.6510e-04 - val_mae: 0.0148\n",
      "Epoch 24/100\n",
      "12228/12228 [==============================] - 8s 672us/step - loss: 3.6419e-04 - mae: 0.0150 - val_loss: 3.6378e-04 - val_mae: 0.0148\n",
      "Epoch 25/100\n",
      "12228/12228 [==============================] - 8s 683us/step - loss: 3.6380e-04 - mae: 0.0150 - val_loss: 3.6081e-04 - val_mae: 0.0150\n",
      "Epoch 26/100\n",
      "12228/12228 [==============================] - 8s 686us/step - loss: 3.6402e-04 - mae: 0.0150 - val_loss: 3.6255e-04 - val_mae: 0.0148\n",
      "Epoch 27/100\n",
      "12228/12228 [==============================] - 8s 687us/step - loss: 3.6392e-04 - mae: 0.0150 - val_loss: 3.6116e-04 - val_mae: 0.0149\n",
      "Epoch 28/100\n",
      "12228/12228 [==============================] - 8s 642us/step - loss: 3.6412e-04 - mae: 0.0150 - val_loss: 3.6069e-04 - val_mae: 0.0150\n",
      "Epoch 29/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6391e-04 - mae: 0.0150 - val_loss: 3.6062e-04 - val_mae: 0.0150\n",
      "Epoch 30/100\n",
      "12228/12228 [==============================] - 8s 651us/step - loss: 3.6380e-04 - mae: 0.0150 - val_loss: 3.6215e-04 - val_mae: 0.0149\n",
      "Epoch 31/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6391e-04 - mae: 0.0150 - val_loss: 3.6099e-04 - val_mae: 0.0150\n",
      "Epoch 32/100\n",
      "12228/12228 [==============================] - 8s 635us/step - loss: 3.6352e-04 - mae: 0.0150 - val_loss: 3.6932e-04 - val_mae: 0.0150\n",
      "Epoch 33/100\n",
      "12228/12228 [==============================] - 8s 672us/step - loss: 3.6261e-04 - mae: 0.0150 - val_loss: 3.5712e-04 - val_mae: 0.0149\n",
      "Epoch 34/100\n",
      "12228/12228 [==============================] - 8s 646us/step - loss: 3.6184e-04 - mae: 0.0150 - val_loss: 3.6126e-04 - val_mae: 0.0149\n",
      "Epoch 35/100\n",
      "12228/12228 [==============================] - 8s 649us/step - loss: 3.6153e-04 - mae: 0.0150 - val_loss: 3.6687e-04 - val_mae: 0.0154\n",
      "Epoch 36/100\n",
      "12228/12228 [==============================] - 8s 643us/step - loss: 3.6152e-04 - mae: 0.0150 - val_loss: 3.6429e-04 - val_mae: 0.0153\n",
      "Epoch 37/100\n",
      "12228/12228 [==============================] - 8s 646us/step - loss: 3.6135e-04 - mae: 0.0150 - val_loss: 3.5932e-04 - val_mae: 0.0148\n",
      "Epoch 38/100\n",
      "12228/12228 [==============================] - 8s 680us/step - loss: 3.6106e-04 - mae: 0.0150 - val_loss: 3.5685e-04 - val_mae: 0.0149\n",
      "Epoch 39/100\n",
      "12228/12228 [==============================] - 8s 645us/step - loss: 3.6131e-04 - mae: 0.0150 - val_loss: 3.5941e-04 - val_mae: 0.0149\n",
      "Epoch 40/100\n",
      "12228/12228 [==============================] - 8s 645us/step - loss: 3.6105e-04 - mae: 0.0150 - val_loss: 3.5863e-04 - val_mae: 0.0147\n",
      "Epoch 41/100\n",
      "12228/12228 [==============================] - 8s 643us/step - loss: 3.6098e-04 - mae: 0.0150 - val_loss: 3.5949e-04 - val_mae: 0.0151\n",
      "Epoch 42/100\n",
      "12228/12228 [==============================] - 8s 644us/step - loss: 3.6118e-04 - mae: 0.0150 - val_loss: 3.5732e-04 - val_mae: 0.0150\n",
      "Epoch 43/100\n",
      "12228/12228 [==============================] - 8s 646us/step - loss: 3.6080e-04 - mae: 0.0150 - val_loss: 3.5696e-04 - val_mae: 0.0150\n",
      "Epoch 44/100\n",
      "12228/12228 [==============================] - 8s 634us/step - loss: 3.6092e-04 - mae: 0.0150 - val_loss: 3.6208e-04 - val_mae: 0.0151\n",
      "Epoch 45/100\n",
      "12228/12228 [==============================] - 8s 631us/step - loss: 3.6092e-04 - mae: 0.0150 - val_loss: 3.5692e-04 - val_mae: 0.0148\n",
      "Epoch 46/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6070e-04 - mae: 0.0150 - val_loss: 3.6260e-04 - val_mae: 0.0151\n",
      "Epoch 47/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6104e-04 - mae: 0.0150 - val_loss: 3.6400e-04 - val_mae: 0.0148\n",
      "Epoch 48/100\n",
      "12228/12228 [==============================] - 8s 641us/step - loss: 3.6081e-04 - mae: 0.0150 - val_loss: 3.5774e-04 - val_mae: 0.0149\n",
      "   1/5241 [..............................] - ETA: 0s - loss: 2.3569e-04 - mae: 0.0115WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5241/5241 [==============================] - 2s 393us/step - loss: 3.5659e-04 - mae: 0.0149\n",
      "Test Loss: 0.0003565888910088688\n",
      "Test MAE: 0.014893828891217709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('train.csv') \n",
    "\n",
    "# 입력과 출력 데이터 나누기\n",
    "X = data.drop(['FloodProbability','id'], axis=1).values  # 입력 특성\n",
    "y = data['FloodProbability'].values  # 출력 타겟\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=35)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)\n",
    "\n",
    "# Test Loss: 0.0003612188156694174\n",
    "# Test MAE: 0.014995004050433636\n",
    "# 기본\n",
    "\n",
    "# Test Loss: 0.0003593358560465276\n",
    "# Test MAE: 0.014905383810400963\n",
    "# best_model.h5 추가\n",
    "\n",
    "# Test Loss: 0.00035975821083411574\n",
    "# Test MAE: 0.01483593787997961\n",
    "# adam -> rmsprop\n",
    "\n",
    "# Test Loss: 0.00035775540163740516\n",
    "# Test MAE: 0.0148658761754632\n",
    "# batch size 32 -> 64\n",
    "\n",
    "# Test Loss: 0.00035533090704120696\n",
    "# Test MAE: 0.01483441423624754\n",
    "# rmsprop -> adam\n",
    "\n",
    "# Test Loss: 0.0003565888910088688\n",
    "# Test MAE: 0.014893828891217709\n",
    "# 뉴런 64 -> 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17469/17469 [==============================] - 11s 641us/step - loss: 8.1638e-04 - mae: 0.0186 - val_loss: 3.7809e-04 - val_mae: 0.0154\n",
      "Epoch 2/100\n",
      "17469/17469 [==============================] - 10s 598us/step - loss: 3.7221e-04 - mae: 0.0152 - val_loss: 3.7409e-04 - val_mae: 0.0155\n",
      "Epoch 3/100\n",
      "17469/17469 [==============================] - 10s 600us/step - loss: 3.6645e-04 - mae: 0.0151 - val_loss: 3.6662e-04 - val_mae: 0.0148\n",
      "Epoch 4/100\n",
      "17469/17469 [==============================] - 11s 618us/step - loss: 3.6385e-04 - mae: 0.0150 - val_loss: 3.6553e-04 - val_mae: 0.0153\n",
      "Epoch 5/100\n",
      "17469/17469 [==============================] - 11s 621us/step - loss: 3.6270e-04 - mae: 0.0150 - val_loss: 3.5931e-04 - val_mae: 0.0149\n",
      "Epoch 6/100\n",
      "17469/17469 [==============================] - 11s 617us/step - loss: 3.6177e-04 - mae: 0.0149 - val_loss: 3.6579e-04 - val_mae: 0.0153\n",
      "Epoch 7/100\n",
      "17469/17469 [==============================] - 11s 612us/step - loss: 3.6129e-04 - mae: 0.0149 - val_loss: 3.5939e-04 - val_mae: 0.0151\n",
      "Epoch 8/100\n",
      "17469/17469 [==============================] - 11s 648us/step - loss: 3.6086e-04 - mae: 0.0149 - val_loss: 3.5870e-04 - val_mae: 0.0147\n",
      "Epoch 9/100\n",
      "17469/17469 [==============================] - 11s 619us/step - loss: 3.6085e-04 - mae: 0.0149 - val_loss: 3.6168e-04 - val_mae: 0.0152\n",
      "Epoch 10/100\n",
      "17469/17469 [==============================] - 11s 616us/step - loss: 3.6052e-04 - mae: 0.0149 - val_loss: 3.6038e-04 - val_mae: 0.0151\n",
      "Epoch 11/100\n",
      "17469/17469 [==============================] - 11s 611us/step - loss: 3.6030e-04 - mae: 0.0149 - val_loss: 3.5793e-04 - val_mae: 0.0149\n",
      "Epoch 12/100\n",
      "17469/17469 [==============================] - 11s 620us/step - loss: 3.6039e-04 - mae: 0.0149 - val_loss: 3.6245e-04 - val_mae: 0.0147\n",
      "Epoch 13/100\n",
      "17469/17469 [==============================] - 11s 617us/step - loss: 3.6010e-04 - mae: 0.0149 - val_loss: 3.7185e-04 - val_mae: 0.0155\n",
      "Epoch 14/100\n",
      "17469/17469 [==============================] - 11s 614us/step - loss: 3.6007e-04 - mae: 0.0149 - val_loss: 3.5897e-04 - val_mae: 0.0150\n",
      "Epoch 15/100\n",
      "17469/17469 [==============================] - 11s 621us/step - loss: 3.5990e-04 - mae: 0.0149 - val_loss: 3.6258e-04 - val_mae: 0.0148\n",
      "Epoch 16/100\n",
      "17469/17469 [==============================] - 11s 641us/step - loss: 3.5988e-04 - mae: 0.0149 - val_loss: 3.5750e-04 - val_mae: 0.0148\n",
      "Epoch 17/100\n",
      "17469/17469 [==============================] - 11s 622us/step - loss: 3.5969e-04 - mae: 0.0149 - val_loss: 3.5728e-04 - val_mae: 0.0149\n",
      "Epoch 18/100\n",
      "17469/17469 [==============================] - 11s 625us/step - loss: 3.5988e-04 - mae: 0.0149 - val_loss: 3.5843e-04 - val_mae: 0.0151\n",
      "Epoch 19/100\n",
      "17469/17469 [==============================] - 11s 619us/step - loss: 3.5976e-04 - mae: 0.0149 - val_loss: 3.5878e-04 - val_mae: 0.0147\n",
      "Epoch 20/100\n",
      "17469/17469 [==============================] - 11s 635us/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5639e-04 - val_mae: 0.0148\n",
      "Epoch 21/100\n",
      "17469/17469 [==============================] - 11s 626us/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.6119e-04 - val_mae: 0.0151\n",
      "Epoch 22/100\n",
      "17469/17469 [==============================] - 11s 626us/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5641e-04 - val_mae: 0.0149\n",
      "Epoch 23/100\n",
      "17469/17469 [==============================] - 11s 624us/step - loss: 3.5957e-04 - mae: 0.0149 - val_loss: 3.6488e-04 - val_mae: 0.0147\n",
      "Epoch 24/100\n",
      "17469/17469 [==============================] - 10s 597us/step - loss: 3.5950e-04 - mae: 0.0149 - val_loss: 3.6638e-04 - val_mae: 0.0154\n",
      "Epoch 25/100\n",
      "17469/17469 [==============================] - 11s 622us/step - loss: 3.5943e-04 - mae: 0.0149 - val_loss: 3.5595e-04 - val_mae: 0.0147\n",
      "Epoch 26/100\n",
      "17469/17469 [==============================] - 10s 599us/step - loss: 3.5943e-04 - mae: 0.0149 - val_loss: 3.5667e-04 - val_mae: 0.0148\n",
      "Epoch 27/100\n",
      "17469/17469 [==============================] - 11s 609us/step - loss: 3.5949e-04 - mae: 0.0149 - val_loss: 3.6003e-04 - val_mae: 0.0151\n",
      "Epoch 28/100\n",
      "17469/17469 [==============================] - 11s 622us/step - loss: 3.5935e-04 - mae: 0.0149 - val_loss: 3.5590e-04 - val_mae: 0.0149\n",
      "Epoch 29/100\n",
      "17469/17469 [==============================] - 10s 599us/step - loss: 3.5932e-04 - mae: 0.0149 - val_loss: 3.5691e-04 - val_mae: 0.0149\n",
      "Epoch 30/100\n",
      "17469/17469 [==============================] - 11s 601us/step - loss: 3.5917e-04 - mae: 0.0149 - val_loss: 3.5990e-04 - val_mae: 0.0148\n",
      "Epoch 31/100\n",
      "17469/17469 [==============================] - 10s 599us/step - loss: 3.5943e-04 - mae: 0.0149 - val_loss: 3.6286e-04 - val_mae: 0.0148\n",
      "Epoch 32/100\n",
      "17469/17469 [==============================] - 10s 599us/step - loss: 3.5924e-04 - mae: 0.0149 - val_loss: 3.5812e-04 - val_mae: 0.0150\n",
      "Epoch 33/100\n",
      "17469/17469 [==============================] - 10s 598us/step - loss: 3.5920e-04 - mae: 0.0149 - val_loss: 3.5984e-04 - val_mae: 0.0147\n",
      "Epoch 34/100\n",
      "17469/17469 [==============================] - 11s 602us/step - loss: 3.5916e-04 - mae: 0.0149 - val_loss: 3.5648e-04 - val_mae: 0.0148\n",
      "Epoch 35/100\n",
      "17469/17469 [==============================] - 11s 603us/step - loss: 3.5921e-04 - mae: 0.0149 - val_loss: 3.5667e-04 - val_mae: 0.0149\n",
      "Epoch 36/100\n",
      "17469/17469 [==============================] - 11s 606us/step - loss: 3.5918e-04 - mae: 0.0149 - val_loss: 3.6238e-04 - val_mae: 0.0147\n",
      "Epoch 37/100\n",
      "17469/17469 [==============================] - 10s 599us/step - loss: 3.5911e-04 - mae: 0.0149 - val_loss: 3.5774e-04 - val_mae: 0.0148\n",
      "Epoch 38/100\n",
      "17469/17469 [==============================] - 10s 593us/step - loss: 3.5919e-04 - mae: 0.0149 - val_loss: 3.5698e-04 - val_mae: 0.0149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.576352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.451702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.454445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.472365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.472290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957          0.576352\n",
       "1  1117958          0.451702\n",
       "2  1117959          0.454445\n",
       "3  1117960          0.472365\n",
       "4  1117961          0.472290"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values  # 훈련 데이터 입력 특성\n",
    "y_train = data_train['FloodProbability'].values  # 훈련 데이터 타겟 변수\n",
    "X_test = data_test.drop(['id'], axis=1).values  # 테스트 데이터 입력 특성\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "submission_df.head()\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission_ann.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_df.to_csv('submission_ann.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0712075 ],\n",
       "       [-0.07862947],\n",
       "       [-0.16359659],\n",
       "       ...,\n",
       "       [ 0.00411901],\n",
       "       [-0.00835801],\n",
       "       [ 0.09335136]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24456/24456 [==============================] - 22s 892us/step - loss: 8.7832e-04 - mae: 0.0195 - val_loss: 4.7691e-04 - val_mae: 0.0177\n",
      "Epoch 2/100\n",
      "24456/24456 [==============================] - 21s 870us/step - loss: 4.0456e-04 - mae: 0.0158 - val_loss: 4.4781e-04 - val_mae: 0.0169\n",
      "Epoch 3/100\n",
      "24456/24456 [==============================] - 21s 862us/step - loss: 3.9789e-04 - mae: 0.0157 - val_loss: 5.3456e-04 - val_mae: 0.0188\n",
      "Epoch 4/100\n",
      "24456/24456 [==============================] - 22s 886us/step - loss: 3.9461e-04 - mae: 0.0156 - val_loss: 4.5319e-04 - val_mae: 0.0171\n",
      "Epoch 5/100\n",
      "24456/24456 [==============================] - 22s 884us/step - loss: 3.9419e-04 - mae: 0.0156 - val_loss: 5.1101e-04 - val_mae: 0.0184\n",
      "Epoch 6/100\n",
      "24456/24456 [==============================] - 22s 893us/step - loss: 3.9369e-04 - mae: 0.0156 - val_loss: 4.9989e-04 - val_mae: 0.0182\n",
      "Epoch 7/100\n",
      "24456/24456 [==============================] - 21s 854us/step - loss: 3.9415e-04 - mae: 0.0156 - val_loss: 4.6310e-04 - val_mae: 0.0173\n",
      "Epoch 8/100\n",
      "24456/24456 [==============================] - 21s 869us/step - loss: 3.9447e-04 - mae: 0.0156 - val_loss: 5.0028e-04 - val_mae: 0.0182\n",
      "Epoch 9/100\n",
      "24456/24456 [==============================] - 22s 881us/step - loss: 3.9429e-04 - mae: 0.0156 - val_loss: 5.1661e-04 - val_mae: 0.0184\n",
      "Epoch 10/100\n",
      "24456/24456 [==============================] - 21s 869us/step - loss: 3.9383e-04 - mae: 0.0155 - val_loss: 5.2422e-04 - val_mae: 0.0187\n",
      "Epoch 11/100\n",
      "24456/24456 [==============================] - 22s 898us/step - loss: 3.9356e-04 - mae: 0.0156 - val_loss: 4.8156e-04 - val_mae: 0.0177\n",
      "Epoch 12/100\n",
      "24456/24456 [==============================] - 22s 880us/step - loss: 3.9385e-04 - mae: 0.0156 - val_loss: 4.9600e-04 - val_mae: 0.0180\n",
      "5241/5241 [==============================] - 2s 426us/step - loss: 4.4515e-04 - mae: 0.0169\n",
      "Test Loss: 0.00044515429181046784\n",
      "Test MAE: 0.016903633251786232\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv') \n",
    "\n",
    "X = data.drop(['FloodProbability', 'id'], axis=1).values\n",
    "y = data['FloodProbability'].values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=35)\n",
    "\n",
    "# 모델 설계\n",
    "# 은닉층 추가\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# 조기 종료 및 모델 체크포인트 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# 가장 좋은 모델 로드\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mm\\AppData\\Local\\Temp\\ipykernel_21460\\1770470864.py:33: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('train.csv') \n",
    "\n",
    "# 입력과 출력 데이터 나누기\n",
    "X = data.drop(['FloodProbability','id'], axis=1).values\n",
    "y = data['FloodProbability'].values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=35)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "# 모델 생성 함수\n",
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# KerasRegressor 모델 생성\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# 하이퍼파라미터 그리드\n",
    "param_grid = {'batch_size': [16, 32, 64],\n",
    "              'epochs': [50, 100, 200],\n",
    "              'optimizer': [Adam(), RMSprop()]}\n",
    "\n",
    "# 그리드 서치\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values\n",
    "y_train = data_train['FloodProbability'].values\n",
    "\n",
    "X_test = data_test.drop(['id'], axis=1).values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 6.5333e-04 - mae: 0.0175 - val_loss: 3.7532e-04 - val_mae: 0.0156\n",
      "Epoch 2/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.7268e-04 - mae: 0.0152 - val_loss: 3.6519e-04 - val_mae: 0.0152\n",
      "Epoch 3/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6843e-04 - mae: 0.0151 - val_loss: 3.7696e-04 - val_mae: 0.0156\n",
      "Epoch 4/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6711e-04 - mae: 0.0151 - val_loss: 3.5927e-04 - val_mae: 0.0148\n",
      "Epoch 5/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6605e-04 - mae: 0.0150 - val_loss: 3.6076e-04 - val_mae: 0.0149\n",
      "Epoch 6/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6534e-04 - mae: 0.0150 - val_loss: 3.6253e-04 - val_mae: 0.0149\n",
      "Epoch 7/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6459e-04 - mae: 0.0150 - val_loss: 3.6094e-04 - val_mae: 0.0150\n",
      "Epoch 8/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6393e-04 - mae: 0.0150 - val_loss: 3.5833e-04 - val_mae: 0.0149\n",
      "Epoch 9/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6305e-04 - mae: 0.0150 - val_loss: 3.6792e-04 - val_mae: 0.0153\n",
      "Epoch 10/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6290e-04 - mae: 0.0150 - val_loss: 3.8121e-04 - val_mae: 0.0149\n",
      "Epoch 11/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6251e-04 - mae: 0.0150 - val_loss: 3.5880e-04 - val_mae: 0.0150\n",
      "Epoch 12/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6197e-04 - mae: 0.0150 - val_loss: 3.6681e-04 - val_mae: 0.0148\n",
      "Epoch 13/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6195e-04 - mae: 0.0150 - val_loss: 3.6766e-04 - val_mae: 0.0153\n",
      "Epoch 14/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6149e-04 - mae: 0.0149 - val_loss: 3.6349e-04 - val_mae: 0.0150\n",
      "Epoch 15/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6170e-04 - mae: 0.0149 - val_loss: 3.6193e-04 - val_mae: 0.0148\n",
      "Epoch 16/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6157e-04 - mae: 0.0150 - val_loss: 3.6223e-04 - val_mae: 0.0149\n",
      "Epoch 17/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6149e-04 - mae: 0.0149 - val_loss: 3.6335e-04 - val_mae: 0.0152\n",
      "Epoch 18/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6138e-04 - mae: 0.0149 - val_loss: 3.6085e-04 - val_mae: 0.0151\n",
      "Epoch 19/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6098e-04 - mae: 0.0149 - val_loss: 3.6137e-04 - val_mae: 0.0151\n",
      "Epoch 20/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6100e-04 - mae: 0.0149 - val_loss: 3.6186e-04 - val_mae: 0.0150\n",
      "Epoch 21/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6079e-04 - mae: 0.0149 - val_loss: 3.6074e-04 - val_mae: 0.0147\n",
      "Epoch 22/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6055e-04 - mae: 0.0149 - val_loss: 3.6117e-04 - val_mae: 0.0151\n",
      "Epoch 23/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6054e-04 - mae: 0.0149 - val_loss: 3.7965e-04 - val_mae: 0.0158\n",
      "Epoch 24/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6045e-04 - mae: 0.0149 - val_loss: 3.5664e-04 - val_mae: 0.0148\n",
      "Epoch 25/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6037e-04 - mae: 0.0149 - val_loss: 3.6083e-04 - val_mae: 0.0148\n",
      "Epoch 26/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.6023e-04 - mae: 0.0149 - val_loss: 3.5677e-04 - val_mae: 0.0148\n",
      "Epoch 27/30\n",
      "24456/24456 [==============================] - 36s 1ms/step - loss: 3.5998e-04 - mae: 0.0149 - val_loss: 3.5798e-04 - val_mae: 0.0147\n",
      "Epoch 28/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6006e-04 - mae: 0.0149 - val_loss: 3.6298e-04 - val_mae: 0.0152\n",
      "Epoch 29/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6023e-04 - mae: 0.0149 - val_loss: 3.6236e-04 - val_mae: 0.0152\n",
      "Epoch 30/30\n",
      "24456/24456 [==============================] - 35s 1ms/step - loss: 3.6011e-04 - mae: 0.0149 - val_loss: 3.6831e-04 - val_mae: 0.0154\n",
      "5241/5241 [==============================] - 5s 946us/step - loss: 3.6813e-04 - mae: 0.0154\n",
      "Test Loss: 0.0003681324888020754\n",
      "Test MAE: 0.015425443649291992\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# 입력과 출력 데이터 나누기\n",
    "X = data.drop(['FloodProbability','id'], axis=1).values\n",
    "y = data['FloodProbability'].values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=35)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27949/27949 [==============================] - 41s 1ms/step - loss: 6.0796e-04 - mae: 0.0172 - val_loss: 3.9237e-04 - val_mae: 0.0160\n",
      "Epoch 2/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.7322e-04 - mae: 0.0152 - val_loss: 3.8872e-04 - val_mae: 0.0150\n",
      "Epoch 3/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6918e-04 - mae: 0.0151 - val_loss: 3.6249e-04 - val_mae: 0.0151\n",
      "Epoch 4/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6679e-04 - mae: 0.0151 - val_loss: 3.6367e-04 - val_mae: 0.0152\n",
      "Epoch 5/50\n",
      "27949/27949 [==============================] - 38s 1ms/step - loss: 3.6489e-04 - mae: 0.0150 - val_loss: 3.6551e-04 - val_mae: 0.0153\n",
      "Epoch 6/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6376e-04 - mae: 0.0150 - val_loss: 3.5923e-04 - val_mae: 0.0148\n",
      "Epoch 7/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6278e-04 - mae: 0.0150 - val_loss: 3.5992e-04 - val_mae: 0.0150\n",
      "Epoch 8/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6182e-04 - mae: 0.0149 - val_loss: 3.5814e-04 - val_mae: 0.0149\n",
      "Epoch 9/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6130e-04 - mae: 0.0149 - val_loss: 3.6010e-04 - val_mae: 0.0149\n",
      "Epoch 10/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6105e-04 - mae: 0.0149 - val_loss: 3.5936e-04 - val_mae: 0.0150\n",
      "Epoch 11/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6090e-04 - mae: 0.0149 - val_loss: 3.6246e-04 - val_mae: 0.0149\n",
      "Epoch 12/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6081e-04 - mae: 0.0149 - val_loss: 3.5822e-04 - val_mae: 0.0150\n",
      "Epoch 13/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6076e-04 - mae: 0.0149 - val_loss: 3.6270e-04 - val_mae: 0.0153\n",
      "Epoch 14/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6069e-04 - mae: 0.0149 - val_loss: 3.5828e-04 - val_mae: 0.0149\n",
      "Epoch 15/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6046e-04 - mae: 0.0149 - val_loss: 3.6168e-04 - val_mae: 0.0148\n",
      "Epoch 16/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6031e-04 - mae: 0.0149 - val_loss: 3.5849e-04 - val_mae: 0.0148\n",
      "Epoch 17/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6038e-04 - mae: 0.0149 - val_loss: 3.5831e-04 - val_mae: 0.0148\n",
      "Epoch 18/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.6016e-04 - mae: 0.0149 - val_loss: 3.6075e-04 - val_mae: 0.0148\n",
      "Epoch 19/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6029e-04 - mae: 0.0149 - val_loss: 3.7849e-04 - val_mae: 0.0148\n",
      "Epoch 20/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6029e-04 - mae: 0.0149 - val_loss: 3.5980e-04 - val_mae: 0.0147\n",
      "Epoch 21/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6018e-04 - mae: 0.0149 - val_loss: 3.6103e-04 - val_mae: 0.0148\n",
      "Epoch 22/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5990e-04 - mae: 0.0149 - val_loss: 3.6147e-04 - val_mae: 0.0151\n",
      "Epoch 23/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.6002e-04 - mae: 0.0149 - val_loss: 3.6160e-04 - val_mae: 0.0151\n",
      "Epoch 24/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5991e-04 - mae: 0.0149 - val_loss: 3.5755e-04 - val_mae: 0.0150\n",
      "Epoch 25/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5998e-04 - mae: 0.0149 - val_loss: 3.6838e-04 - val_mae: 0.0155\n",
      "Epoch 26/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5976e-04 - mae: 0.0149 - val_loss: 3.5748e-04 - val_mae: 0.0148\n",
      "Epoch 27/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5970e-04 - mae: 0.0149 - val_loss: 3.5834e-04 - val_mae: 0.0147\n",
      "Epoch 28/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5960e-04 - mae: 0.0149 - val_loss: 3.5635e-04 - val_mae: 0.0148\n",
      "Epoch 29/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5950e-04 - mae: 0.0149 - val_loss: 3.6449e-04 - val_mae: 0.0146\n",
      "Epoch 30/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5828e-04 - val_mae: 0.0151\n",
      "Epoch 31/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5952e-04 - mae: 0.0149 - val_loss: 3.5993e-04 - val_mae: 0.0151\n",
      "Epoch 32/50\n",
      "27949/27949 [==============================] - 41s 1ms/step - loss: 3.5962e-04 - mae: 0.0149 - val_loss: 3.5669e-04 - val_mae: 0.0149\n",
      "Epoch 33/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5926e-04 - mae: 0.0149 - val_loss: 3.5813e-04 - val_mae: 0.0150\n",
      "Epoch 34/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5947e-04 - mae: 0.0149 - val_loss: 3.6359e-04 - val_mae: 0.0146\n",
      "Epoch 35/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5934e-04 - mae: 0.0149 - val_loss: 3.5838e-04 - val_mae: 0.0150\n",
      "Epoch 36/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5945e-04 - mae: 0.0149 - val_loss: 3.5925e-04 - val_mae: 0.0151\n",
      "Epoch 37/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5952e-04 - mae: 0.0149 - val_loss: 3.5879e-04 - val_mae: 0.0148\n",
      "Epoch 38/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5932e-04 - mae: 0.0149 - val_loss: 3.6859e-04 - val_mae: 0.0148\n",
      "Epoch 39/50\n",
      "27949/27949 [==============================] - 40s 1ms/step - loss: 3.5943e-04 - mae: 0.0149 - val_loss: 3.5752e-04 - val_mae: 0.0149\n",
      "Epoch 40/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5914e-04 - mae: 0.0149 - val_loss: 3.5834e-04 - val_mae: 0.0150\n",
      "Epoch 41/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5936e-04 - mae: 0.0149 - val_loss: 3.5798e-04 - val_mae: 0.0149\n",
      "Epoch 42/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5930e-04 - mae: 0.0149 - val_loss: 3.5751e-04 - val_mae: 0.0147\n",
      "Epoch 43/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5927e-04 - mae: 0.0149 - val_loss: 3.6676e-04 - val_mae: 0.0153\n",
      "Epoch 44/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5916e-04 - mae: 0.0149 - val_loss: 3.5989e-04 - val_mae: 0.0151\n",
      "Epoch 45/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5929e-04 - mae: 0.0149 - val_loss: 3.5817e-04 - val_mae: 0.0147\n",
      "Epoch 46/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5911e-04 - mae: 0.0149 - val_loss: 3.5968e-04 - val_mae: 0.0151\n",
      "Epoch 47/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5925e-04 - mae: 0.0149 - val_loss: 3.6505e-04 - val_mae: 0.0147\n",
      "Epoch 48/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5922e-04 - mae: 0.0149 - val_loss: 3.6508e-04 - val_mae: 0.0147\n",
      "Epoch 49/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5920e-04 - mae: 0.0149 - val_loss: 3.7208e-04 - val_mae: 0.0156\n",
      "Epoch 50/50\n",
      "27949/27949 [==============================] - 39s 1ms/step - loss: 3.5931e-04 - mae: 0.0149 - val_loss: 3.6481e-04 - val_mae: 0.0147\n",
      "23291/23291 [==============================] - 18s 757us/step\n"
     ]
    }
   ],
   "source": [
    "# 입력과 출력 데이터 분할\n",
    "X_train = data_train.drop(['FloodProbability', 'id'], axis=1).values\n",
    "y_train = data_train['FloodProbability'].values\n",
    "\n",
    "X_test = data_test.drop(['id'], axis=1).values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 테스트 데이터의 타겟 변수 예측\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 변환\n",
    "submission_df = pd.DataFrame({'id': data_test['id'], 'FloodProbability': y_pred.flatten()})\n",
    "\n",
    "# CSV 파일로 저장\n",
    "submission_df.to_csv('submission2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "page",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
