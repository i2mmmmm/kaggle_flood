{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOH7GSoJ9t+Az9K4OMm1iK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i2mmmmm/kaggle_flood/blob/main/colab/4.%20ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME']='mmmmmlee'\n",
        "os.environ['KAGGLE_KEY']='b4527f98e27813c6dae3fb199096dcb5'"
      ],
      "metadata": {
        "id": "fs6gowPQ409q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c Playground-series-s4e5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Xevuva5hJF",
        "outputId": "3d76572f-eb77-4bcb-8833-8692f036083d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Playground-series-s4e5.zip to /content\n",
            " 61% 17.0M/28.0M [00:00<00:00, 64.4MB/s]\n",
            "100% 28.0M/28.0M [00:00<00:00, 92.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'Playground-series-s4e5.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3TOjJfH5tZc",
        "outputId": "77974325-6037-4890-e041-75eec8416d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Playground-series-s4e5.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "from sklearn.ensemble import VotingRegressor, BaggingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import BayesianRidge, SGDRegressor, Ridge\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "387z09Uk6WPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "vq29Kz8I76PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 표준화, 스케일링\n",
        "scaler = StandardScaler()\n",
        "X = train.drop(columns=['FloodProbability', 'id'])\n",
        "y = train['FloodProbability']\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "MWnmqYIrNEiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형회귀_baseline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=35)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('R2 Score:', r2_score(y_test, y_pred))\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZM072ebOAAk",
        "outputId": "5bb1e7c9-ec6a-4ae1-dd70-bcfbf3fc3771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.8449835489068076\n",
            "MSE: 0.00040395088979260915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시 feature engineering\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "def simplified_getFeats(df):\n",
        "    num_cols = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
        "\n",
        "    scaler = StandardScaler().fit(df[num_cols])\n",
        "    df[num_cols] = scaler.transform(df[num_cols])  # Scale early\n",
        "\n",
        "    # Basic Stats\n",
        "    df['mean'] = df[num_cols].mean(axis=1)\n",
        "    df['std'] = df[num_cols].std(axis=1)\n",
        "    df['max'] = df[num_cols].max(axis=1)\n",
        "    df['min'] = df[num_cols].min(axis=1)\n",
        "\n",
        "    # Interaction Features (Simplified)\n",
        "    df['Climate_Risk'] = df['MonsoonIntensity'] * df['ClimateChange']\n",
        "    df['Infrastructure_Risk'] = df['DamsQuality'] * df['DrainageSystems']\n",
        "    df['wet_Risk'] = df['WetlandLoss'] * df['Encroachments']\n",
        "\n",
        "    return df\n",
        "\n",
        "train_simp = simplified_getFeats(train)\n",
        "\n",
        "X = train_simp.drop(columns=['FloodProbability', 'id'])\n",
        "y = train_simp['FloodProbability']"
      ],
      "metadata": {
        "id": "mQlKyqBzEBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM 모델 학습\n",
        "\n",
        "lgbm_params = {\n",
        "    'num_leaves': 183,\n",
        "    'learning_rate': 0.01183688880802108,\n",
        "    'n_estimators': 577,\n",
        "    'subsample_for_bin': 165697,\n",
        "    'min_child_samples': 114,\n",
        "    'reg_alpha': 2.075080888948164e-06,\n",
        "    'reg_lambda': 3.838938366471552e-07,\n",
        "    'colsample_bytree': 0.9634044234652241,\n",
        "    'subsample': 0.9592138618622019,\n",
        "    'max_depth': 9\n",
        "}\n",
        "\n",
        "model_lgb = lgb.LGBMRegressor(**lgbm_params)\n",
        "model_lgb.fit(X_train, y_train)\n",
        "y_pred_lgb = model_lgb.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn2NkMZENMhJ",
        "outputId": "cbd5b5c7-f539-4fe9-de31-8de24a8a3233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.487907 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1843\n",
            "[LightGBM] [Info] Number of data points in the train set: 1117957, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score 0.504480\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력\n",
        "test_simp['FloodProbability'] = y_pred_lgb\n",
        "test_simp[['id', 'FloodProbability']].to_csv('submission_engi_lgb_para.csv', index=False)"
      ],
      "metadata": {
        "id": "R_zHW9P6Sstw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub1 = pd.read_csv('submission (1).csv')\n",
        "sub2 = pd.read_csv('submission (2).csv')\n",
        "sub3 = pd.read_csv('submission (3).csv')\n",
        "\n",
        "print(sub1.head())\n",
        "print(sub2.head())\n",
        "print(sub3.head())"
      ],
      "metadata": {
        "id": "sIry6fPJrhQi",
        "outputId": "419a0287-092a-42f3-9d09-5b915fab1aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  FloodProbability\n",
            "0  1117957          0.578705\n",
            "1  1117958          0.454723\n",
            "2  1117959          0.448682\n",
            "3  1117960          0.467035\n",
            "4  1117961          0.465906\n",
            "        id  FloodProbability\n",
            "0  1117957          0.577933\n",
            "1  1117958          0.456926\n",
            "2  1117959          0.447441\n",
            "3  1117960          0.464352\n",
            "4  1117961          0.466865\n",
            "        id  FloodProbability\n",
            "0  1117957          0.578782\n",
            "1  1117958          0.454955\n",
            "2  1117959          0.448574\n",
            "3  1117960          0.466518\n",
            "4  1117961          0.466017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 평균 내기\n",
        "ensemble_sub = sub1.copy()\n",
        "ensemble_sub['FloodProbability'] = (sub1['FloodProbability'] + sub2['FloodProbability'] + sub3['FloodProbability']) / 3\n",
        "\n",
        "# 앙상블 결과 저장\n",
        "ensemble_sub.to_csv('submission_ensemble.csv', index=False)"
      ],
      "metadata": {
        "id": "H_VzStiUsLfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble2 = sub2.copy()\n",
        "ensemble2['FloodProbability'] = sub1['FloodProbability']  +sub1['FloodProbability'] - ensemble_sub['FloodProbability']"
      ],
      "metadata": {
        "id": "R81talf8zR5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble2.to_csv('submission_ensemble2.csv', index=False)"
      ],
      "metadata": {
        "id": "jzA4gFUPzpje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ensemble2.head())"
      ],
      "metadata": {
        "id": "HxWTfHJ5sUkv",
        "outputId": "2631a5eb-9e63-4cde-95b7-c4e6b7a47ceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  FloodProbability\n",
            "0  1117957          0.578473\n",
            "1  1117958          0.455535\n",
            "2  1117959          0.448232\n",
            "3  1117960          0.465968\n",
            "4  1117961          0.466263\n"
          ]
        }
      ]
    }
  ]
}