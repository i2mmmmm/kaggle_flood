{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJl6sB8gib+Y1YgMz0XV8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i2mmmmm/kaggle_flood/blob/main/colab/5.%20ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME']='mmmmmlee'\n",
        "os.environ['KAGGLE_KEY']='b4527f98e27813c6dae3fb199096dcb5'"
      ],
      "metadata": {
        "id": "fs6gowPQ409q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c Playground-series-s4e5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Xevuva5hJF",
        "outputId": "0e547f4c-b384-46e0-e0ca-9918f75086e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Playground-series-s4e5.zip to /content\n",
            "\r  0% 0.00/28.0M [00:00<?, ?B/s]\r 64% 18.0M/28.0M [00:00<00:00, 185MB/s]\n",
            "\r100% 28.0M/28.0M [00:00<00:00, 211MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'Playground-series-s4e5.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3TOjJfH5tZc",
        "outputId": "da662400-9750-42bd-a91a-39046bf69be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Playground-series-s4e5.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "from sklearn.ensemble import VotingRegressor, BaggingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import BayesianRidge, SGDRegressor, Ridge\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "387z09Uk6WPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "vq29Kz8I76PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 표준화, 스케일링\n",
        "scaler = StandardScaler()\n",
        "X = train.drop(columns=['FloodProbability', 'id'])\n",
        "y = train['FloodProbability']\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "MWnmqYIrNEiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형회귀_baseline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=35)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('R2 Score:', r2_score(y_test, y_pred))\n",
        "print('MSE:', mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZM072ebOAAk",
        "outputId": "dac8aab4-b0f6-4334-95de-3a33ad2ed0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.8449835489068076\n",
            "MSE: 0.00040395088979260915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시 feature engineering\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "def simplified_getFeats(df):\n",
        "    num_cols = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
        "\n",
        "    scaler = StandardScaler().fit(df[num_cols])\n",
        "    df[num_cols] = scaler.transform(df[num_cols])  # Scale early\n",
        "\n",
        "    BASE_FEATURES = test.columns\n",
        "    df = train.copy()\n",
        "    df['CombinedUrbanImpact'] = df['Urbanization'] * df['PopulationScore']\n",
        "    df['EnvironmentalDegradation'] = df['Deforestation'] + df['Siltation'] + df['WetlandLoss']\n",
        "    df['InfrastructureVulnerability'] = df['DeterioratingInfrastructure'] + df['DrainageSystems'] + df['DamsQuality']\n",
        "    df['NaturalDisasterRisk'] = df['MonsoonIntensity'] + df['ClimateChange'] + df['Landslides'] + df['CoastalVulnerability']\n",
        "    df['ManagementEffectiveness'] = df['RiverManagement'] + df['AgriculturalPractices'] + df['Encroachments'] + df['InadequatePlanning'] + df['PoliticalFactors']\n",
        "    df['Infrastructure_Risk'] = df['DamsQuality'] * df['DrainageSystems']\n",
        "    df['wet_Risk'] = df['WetlandLoss'] * df['Encroachments']\n",
        "\n",
        "    df['total'] = df[BASE_FEATURES].sum(axis=1)\n",
        "    df['mean'] = df[BASE_FEATURES].mean(axis=1)\n",
        "    df['std'] = df[BASE_FEATURES].std(axis=1)\n",
        "    df['max'] = df[BASE_FEATURES].max(axis=1)\n",
        "    df['min'] = df[BASE_FEATURES].min(axis=1)\n",
        "    # df['median'] = df[BASE_FEATURES].median(axis=1)\n",
        "    # df['ptp'] = df[BASE_FEATURES].values.ptp(axis=1)\n",
        "    # df['q25'] = df[BASE_FEATURES].quantile(0.25, axis=1)\n",
        "    # df['q75'] = df[BASE_FEATURES].quantile(0.75, axis=1)\n",
        "    # df['ClimateImpact'] = df['MonsoonIntensity'] + df['ClimateChange']\n",
        "    # df['AnthropogenicPressure'] = df['Deforestation'] + df['Urbanization'] + df['AgriculturalPractices'] + df['Encroachments']\n",
        "    # df['InfrastructureQuality'] = df['DamsQuality'] + df['DrainageSystems'] + df['DeterioratingInfrastructure']\n",
        "    # df['CoastalVulnerabilityTotal'] = df['CoastalVulnerability'] + df['Landslides']\n",
        "    # df['PreventiveMeasuresEfficiency'] = df['RiverManagement'] + df['IneffectiveDisasterPreparedness'] + df['InadequatePlanning']\n",
        "    # df['EcosystemImpact'] = df['WetlandLoss'] + df['Watersheds']\n",
        "    # df['SocioPoliticalContext'] = df['PopulationScore'] * df['PoliticalFactors']\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_simp = simplified_getFeats(train)\n",
        "\n",
        "X = train_simp.drop(columns=['FloodProbability', 'id'])\n",
        "y = train_simp['FloodProbability']\n",
        "\n",
        "# models = {\n",
        "#     'Linear Regression': LinearRegression(),\n",
        "#     'Ridge Regression': Ridge(),\n",
        "#     'SGD Regressor': SGDRegressor(),\n",
        "#     'Bayesian Ridge Regression': BayesianRidge(),\n",
        "#     'Bagging Regressor': BaggingRegressor(estimator=LinearRegression()),\n",
        "#     'XGBoost Regressor': xgb.XGBRegressor(),\n",
        "#     'LightGBM Regressor': lgb.LGBMRegressor(),\n",
        "# }\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=35)\n",
        "\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=35)\n",
        "\n",
        "# for name, model in models.items():\n",
        "#     mse_values = []\n",
        "#     r2_values = []\n",
        "#     for train_index, val_index in kf.split(X):\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "#         model.fit(X_train, y_train)\n",
        "#         y_pred = model.predict(X_val)\n",
        "#         r2_values.append(r2_score(y_val, y_pred))\n",
        "#     avg_r2 = np.mean(r2_values)\n",
        "#     print(f'{name}: R2 = {avg_r2:.4f}')\n"
      ],
      "metadata": {
        "id": "yyW1lq57zHh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시 feature engineering\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "def simplified_getFeats(df):\n",
        "    num_cols = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
        "\n",
        "    scaler = StandardScaler().fit(df[num_cols])\n",
        "    df[num_cols] = scaler.transform(df[num_cols])  # Scale early\n",
        "\n",
        "    # Basic Stats\n",
        "    df['mean'] = df[num_cols].mean(axis=1)\n",
        "    df['std'] = df[num_cols].std(axis=1)\n",
        "    df['max'] = df[num_cols].max(axis=1)\n",
        "    df['min'] = df[num_cols].min(axis=1)\n",
        "\n",
        "    # Interaction Features (Simplified)\n",
        "    df['Climate_Risk'] = df['MonsoonIntensity'] * df['ClimateChange']\n",
        "    df['Infrastructure_Risk'] = df['DamsQuality'] * df['DrainageSystems']\n",
        "    df['wet_Risk'] = df['WetlandLoss'] * df['Encroachments']\n",
        "\n",
        "    return df\n",
        "\n",
        "train_simp = simplified_getFeats(train)\n",
        "test_simp = simplified_getFeats(test)\n"
      ],
      "metadata": {
        "id": "mQlKyqBzEBvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test flood 예측 진행\n",
        "\n",
        "X_train = train_simp.drop(columns=['FloodProbability', 'id'])\n",
        "y_train = train_simp['FloodProbability']\n",
        "X_test = test_simp.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "PuYkRLZJXoff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM 모델 학습\n",
        "\n",
        "lgbm_params = {\n",
        "    'num_leaves': 183,\n",
        "    'learning_rate': 0.01183688880802108,\n",
        "    'n_estimators': 577,\n",
        "    'subsample_for_bin': 165697,\n",
        "    'min_child_samples': 114,\n",
        "    'reg_alpha': 2.075080888948164e-06,\n",
        "    'reg_lambda': 3.838938366471552e-07,\n",
        "    'colsample_bytree': 0.9634044234652241,\n",
        "    'subsample': 0.9592138618622019,\n",
        "    'max_depth': 9\n",
        "}\n",
        "\n",
        "model_lgb = lgb.LGBMRegressor(**lgbm_params)\n",
        "model_lgb.fit(X_train, y_train)\n",
        "y_pred_lgb = model_lgb.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn2NkMZENMhJ",
        "outputId": "cbd5b5c7-f539-4fe9-de31-8de24a8a3233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.487907 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1843\n",
            "[LightGBM] [Info] Number of data points in the train set: 1117957, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score 0.504480\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub1 = pd.read_csv('submission_ensemble.csv')\n",
        "sub2 = pd.read_csv('submission_MLP.csv')\n",
        "sub3 = pd.read_csv('submission_engi_lgb_para.csv')\n"
      ],
      "metadata": {
        "id": "sIry6fPJrhQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 평균 내기\n",
        "ensemble_sub = sub1.copy()\n",
        "ensemble_sub['FloodProbability'] = (sub1['FloodProbability'] + sub2['FloodProbability'] + sub3['FloodProbability']) / 3\n",
        "\n",
        "# 앙상블 결과 저장\n",
        "ensemble_sub.to_csv('submission_ensemble3.csv', index=False)"
      ],
      "metadata": {
        "id": "H_VzStiUsLfl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}